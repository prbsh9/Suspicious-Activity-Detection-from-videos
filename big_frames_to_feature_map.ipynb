{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "big_frames_to_feature_map.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prbsh9/Suspicious-Activity-Detection-from-videos/blob/master/big_frames_to_feature_map.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BffDAcUVbaPG",
        "colab_type": "text"
      },
      "source": [
        "# Importing and syncing stuffs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMJHgMoSAwix",
        "colab_type": "code",
        "outputId": "5e985d71-21c3-4784-ce2b-494af4b70823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')\n",
        "import os\n",
        "path = '/drive/My Drive/suspicious_activity/content/frameEasy'\n",
        "os.chdir(path)\n",
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/drive/My Drive/suspicious_activity/small_one'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21FzSLsVBy0B",
        "colab_type": "code",
        "outputId": "27b0fa81-0c53-4f91-e714-0930bff1b528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "import keras\n",
        "import glob\n",
        "import math\n",
        "import csv\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6gmETUk1Et4",
        "colab_type": "code",
        "outputId": "aed6488f-5b71-4f31-e532-3d60a6d367dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "!du -h "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "142M\t./train/Normal\n",
            "70M\t./train/Abnormal\n",
            "212M\t./train\n",
            "7.4M\t./valid/Abnormal\n",
            "17M\t./valid/Normal\n",
            "24M\t./valid\n",
            "236M\t.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kic_dcvE1FBv",
        "colab_type": "text"
      },
      "source": [
        "# Let's get featuremap of any image given. We will iterate later to get featuremap of all frames "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXMc83neCLUK",
        "colab_type": "code",
        "outputId": "28edfcfc-9e96-43b8-d51b-249853f0e3bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        }
      },
      "source": [
        "model = keras.applications.inception_v3.InceptionV3(input_shape=(299, 299, 3),  include_top=False, weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYuu9UXYAyNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# l = []\n",
        "def getFeature(img_path):\n",
        "  '''Gives the high level feature map of Inception V3 when you input the image..  '''\n",
        "  img = image.load_img(img_path, target_size=(299, 299))\n",
        "  img_data = image.img_to_array(img)\n",
        "  img_data = np.expand_dims(img_data, axis=0)\n",
        "  img_data = preprocess_input(img_data)\n",
        "\n",
        "  feature_map = model.predict(img_data) # (1, 8, 8, 2048) is shape.. \n",
        "  return(feature_map)\n",
        "\n",
        "# array = getFeature('predict5.jpg')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vji8ABJiCMnX",
        "colab_type": "text"
      },
      "source": [
        "# Get frames in sequential order of all videos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX-cDM8DczR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('final.csv', usecols=['video_noext','image'], index_col=False)\n",
        "df1 = pd.read_csv('1.csv', usecols=[3,4], index_col=False, header=None, names= ['vdo', 'img'])\n",
        "df2 = pd.read_csv('2.csv', usecols=[3,4], index_col=False, header=None, names= ['vdo', 'img'])\n",
        "df3 = pd.read_csv('3.csv', usecols=[3,4], index_col=False, header=None, names= ['vdo', 'img'])\n",
        "df4 = pd.read_csv('4.csv', usecols=[3,4], index_col=False, header=None, names= ['vdo', 'img'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDVkdnXtjY3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_N = set(df1['vdo'])\n",
        "train_Ab = set(df2['vdo'])\n",
        "test_Ab = set(df3['vdo'])\n",
        "test_N = set(df4['vdo'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZgwv3FzVUM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def chunks(lst, n):\n",
        "    if len(lst) <= 9:\n",
        "        return([lst])\n",
        "    else:\n",
        "        for i in range(0, len(lst), n):\n",
        "            yield lst[i:i + n]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKbOUOENhVbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train = [train_N]\n",
        "# test = [test_N, test_Ab]\n",
        "# for all in train:\n",
        "#   print( all)\n",
        "#   for vido in all:\n",
        "#     print(vido)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrSC6JxCjSsq",
        "colab_type": "code",
        "outputId": "3f9e185a-e931-48e6-d313-b5d104eadb40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# These are videos... train_N and all being name of videos in set format.. We \n",
        "# are getting names of the frames using the final.csv file.\n",
        "\n",
        "train = [train_Ab]\n",
        "test = [test_N, test_Ab]\n",
        "seq = []\n",
        "for all in train:\n",
        "  # print( filee)\n",
        "  for vido in all:\n",
        "    frames = df.loc[df['video_noext'].eq(vido), 'image']\n",
        "    frames = frames.values.tolist()\n",
        "    sized_frames = chunks(frames, 9)\n",
        "    i = 1\n",
        "    for frames in sized_frames:\n",
        "      \n",
        "      for img in frames:\n",
        "        arr = getFeature(img)\n",
        "        seq.append(arr)\n",
        "\n",
        "      print(vido)  \n",
        "  np.save( os.path.join('data'+'train_Abnormal12'), seq)\n",
        "  print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-808b6198c748>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-6c0baab7d193>\u001b[0m in \u001b[0;36mgetFeature\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;34m'''Gives the high level feature map of Inception V3 when you input the image..  '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mimg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mimg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2766\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: 'train/Abnormal/RoadAccidents124_x264@ 2.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2T6fMtJjAt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = [train_N]\n",
        "test = [ test_Ab]\n",
        "for all in test:\n",
        "  # print( filee)\n",
        "  for vido in all:\n",
        "    frames = df.loc[df['video_noext'].eq(vido), 'image']\n",
        "    frames = frames.values.tolist()\n",
        "    sized_frames = chunks(frames, 9)\n",
        "    i = 1\n",
        "    for frames in sized_frames:\n",
        "      seq = []\n",
        "      for img in frames:\n",
        "        arr = getFeature(img)\n",
        "        seq.append(arr)\n",
        "      np.save( os.path.join('data', vido[:5], vido[6:12] ,vido[15:]+'-features'+str(i)), seq)\n",
        "      i+=1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOKSQ4b0jBnN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGEzWk8_qxI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = [train_Ab]\n",
        "test = [test_N, test_Ab]\n",
        "for all in test:\n",
        "  # print( filee)\n",
        "  for vido in all:\n",
        "    frames = df.loc[df['video_noext'].eq(vido), 'image']\n",
        "    frames = frames.values.tolist()\n",
        "    sized_frames = chunks(frames, 9)\n",
        "    i = 1\n",
        "    for frames in sized_frames:\n",
        "      seq = []\n",
        "      for img in frames:\n",
        "        arr = getFeature(img)\n",
        "        seq.append(arr)\n",
        "      np.save( os.path.join('data', vido[:5], vido[6:12] ,vido[15:]+'-features'+str(i)), seq)\n",
        "      i+=1 \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9KT1BuuS0-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.load('hey.npy')\n",
        "a.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "68siin0uHOPO",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2unArK0FC7f7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lis = [1, 2, 34, 12, 1]\n",
        "list(set(lis))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwlM6hjHBLbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inception_feature_list = []\n",
        "\n",
        "# for idx, dirname in enumerate(['Normal', 'Abnormal']):\n",
        "#     # get the directory names, i.e., 'dogs' or 'cats'\n",
        "#     # ...\n",
        "    \n",
        "#     for i, fname in enumerate(os.listdir(dirname)):\n",
        "#         # process the files under the directory 'dogs' or 'cats'\n",
        "#         # ...\n",
        "#         img_path = dirname+ '/' + fname\n",
        "#         img = image.load_img(img_path, target_size=(224, 224))\n",
        "#         img_data = image.img_to_array(img)\n",
        "#         img_data = np.expand_dims(img_data, axis=0)\n",
        "#         img_data = preprocess_input(img_data)\n",
        "\n",
        "#         inception_feature = model_inception.predict(img_data)\n",
        "#         inception_feature_np = np.array(inception_feature)\n",
        "#         inception_feature_list.append(inception_feature_np.flatten())\n",
        "        \n",
        "# inception_feature_list_np = np.array(inception_feature_list)\n",
        "# kmeans = KMeans(n_clusters=2, random_state=0).fit(inception_feature_list_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0txwzWbWRyNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "data_file = []\n",
        "# train, Normal = 1\n",
        "# valid, Abnormal = 0\n",
        "\n",
        "for img in glob.glob('valid/Normal/'+ '*jpg'):\n",
        "  frame_no = int(img.split('@')[1][:-4])\n",
        "  video_noext = img.split('@')[0]\n",
        "  print(frame_no, 0, 1, video_noext, img)\n",
        "  data_file.append([frame_no, 0, 1, video_noext, img])\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTmNcXxEXLUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = data_file; \n",
        "len(data_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO17U1rvXiIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('./data_file.csv', 'w') as fout:\n",
        "  writer = csv.writer(fout)\n",
        "  writer.writerows(file)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmrSeUMAC9qW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = 'Nkjnaskjdn12_98x8@ 121.jpg'\n",
        "frame_no = int(img.split('@')[1][:-4])\n",
        "video_noext = img.split('@')[0]\n",
        "frame_no, video_noext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Lq97hmhd0Pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# glob.glob('train/Normal/'+ '*jpg')\n",
        "!du -h 'train/Normal'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfbqaD2HIZv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_frames_for_sample(dirtovdo):\n",
        "    \"\"\"Given a sample row from the data file, get all the corresponding frame\n",
        "    filenames.\"\"\"\n",
        "    path = os.path.join('data', sample[0], sample[1])\n",
        "    filename = sample[2]\n",
        "    images = sorted(glob.glob(os.path.join(path, filename + '*jpg')))\n",
        "    return images\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}